{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# camera calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Define the dimensions of checkerboard\n",
    "CHECKERBOARD = (7,7)\n",
    "\n",
    "# Prepare object points\n",
    "objp = np.zeros((CHECKERBOARD[0]*CHECKERBOARD[1],3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:CHECKERBOARD[1],0:CHECKERBOARD[0]].T.reshape(-1,2)\n",
    "\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('calibration_images/checkerboard_test.png')\n",
    "\n",
    "for fname in images:\n",
    "  img = cv2.imread(fname)\n",
    "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "\n",
    "  if ret == True:\n",
    "      objpoints.append(objp)\n",
    "      imgpoints.append(corners)\n",
    "      cv2.drawChessboardCorners(img, CHECKERBOARD, corners, ret)\n",
    "      cv2.imshow('img', img)\n",
    "      cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calibrate the camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# object detection using yolov8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 1 Cardboard, 95.5ms\n",
      "Speed: 4.0ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Class: 0, Confidence: tensor([0.8220]), Box: tensor([[ 40.2158,  28.3944, 609.4910, 422.4665]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "def rescaleFrame(frame, scale=0.75):\n",
    "    #image, video, live capture\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    return cv2.resize(frame, (width, height),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Load YOLO v8 model (use 'yolov8n.pt' as an example; choose appropriate variant)\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"img/smbox.jpeg\")\n",
    "\n",
    "# capture = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     isTrue, image = capture.read()\n",
    "#     # cv.imshow('video', frame)\n",
    "\n",
    "#     if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "#         break\n",
    "\n",
    "image = rescaleFrame(image,0.5)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "# cv2.imshow(\"detected\",results)\n",
    "\n",
    "# Parse results\n",
    "detections = results[0].boxes  # Assuming single image input\n",
    "\n",
    "for box in detections:\n",
    "  cls = int(box.cls)\n",
    "  conf = box.conf\n",
    "  xyxy = box.xyxy  # (x1, y1, x2, y2)\n",
    "  print(f\"Class: {cls}, Confidence: {conf}, Box: {xyxy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotated Bounding Box Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ambbu\\AppData\\Local\\Temp\\ipykernel_25608\\4069726375.py:65: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0: Center: (324.0, 224.5), Width: 393.0, Height: 568.0, Angle: 90.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_image(roi):\n",
    "  \"\"\"\n",
    "  Enhanced image preprocessing with better contrast and noise reduction\n",
    "  \"\"\"\n",
    "  lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "  l, a, b = cv2.split(lab)\n",
    "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "  cl = clahe.apply(l)\n",
    "  enhanced = cv2.merge([cl, a, b])\n",
    "  enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "  return enhanced\n",
    "\n",
    "def get_binary_mask(roi):\n",
    "  \"\"\"\n",
    "  Create a binary mask using multiple thresholding techniques\n",
    "  \"\"\"\n",
    "  enhanced = enhance_image(roi)\n",
    "  gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "  blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "  _, thresh1 = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "  thresh2 = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                cv2.THRESH_BINARY, 11, 2)\n",
    "  binary = cv2.bitwise_or(thresh1, thresh2)\n",
    "  kernel = np.ones((3,3), np.uint8)\n",
    "  binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "  binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "  return binary\n",
    "\n",
    "def get_accurate_rotated_bbox(image, bbox, min_area_ratio=0.1):\n",
    "  \"\"\"\n",
    "  Get accurate rotated bounding box with improved contour detection\n",
    "  \"\"\"\n",
    "  x1, y1, x2, y2 = map(int, bbox)\n",
    "  roi = image[y1:y2, x1:x2]\n",
    "  \n",
    "  roi_height, roi_width = roi.shape[:2]\n",
    "  roi_area = roi_height * roi_width\n",
    "  \n",
    "  binary = get_binary_mask(roi)\n",
    "  contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  \n",
    "  if not contours:\n",
    "      return None, None\n",
    "  \n",
    "  # Filter contours based on area\n",
    "  valid_contours = []\n",
    "  for contour in contours:\n",
    "      area = cv2.contourArea(contour)\n",
    "      if area > roi_area * min_area_ratio:\n",
    "          valid_contours.append(contour)\n",
    "  \n",
    "  if not valid_contours:\n",
    "      return None, None\n",
    "  \n",
    "  c = max(valid_contours, key=cv2.contourArea)\n",
    "  epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "  approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "  hull = cv2.convexHull(approx)\n",
    "  \n",
    "  rotated_rect = cv2.minAreaRect(hull)\n",
    "  box = cv2.boxPoints(rotated_rect)\n",
    "  box = np.int0(box)\n",
    "  \n",
    "  box[:,0] += x1\n",
    "  box[:,1] += y1\n",
    "  \n",
    "  center_x, center_y = rotated_rect[0]\n",
    "  adjusted_rect = ((center_x + x1, center_y + y1), rotated_rect[1], rotated_rect[2])\n",
    "  \n",
    "  return adjusted_rect, box\n",
    "\n",
    "def draw_rotated_bbox(image, rotated_box, color=(0, 255, 0), thickness=2):\n",
    "  \"\"\"\n",
    "  Draw rotated bounding box with additional information\n",
    "  \"\"\"\n",
    "  cv2.polylines(image, [rotated_box], True, color, thickness)\n",
    "  center = np.mean(rotated_box, axis=0).astype(int)\n",
    "  cv2.circle(image, tuple(center), 3, (0, 0, 255), -1)\n",
    "  return image\n",
    "\n",
    "# Main processing function\n",
    "def process_detections(image, detections):\n",
    "  \"\"\"\n",
    "  Process image with all detections\n",
    "  \"\"\"\n",
    "  processed_image = image.copy()\n",
    "  \n",
    "  for box in detections:\n",
    "      # Convert tensor values to Python scalars\n",
    "      cls = int(box.cls.item())  # Convert class tensor to int\n",
    "      conf = float(box.conf.item())  # Convert confidence tensor to float\n",
    "      xyxy = [float(x) for x in box.xyxy[0]]  # Convert bbox coordinates to float\n",
    "      \n",
    "      rotated_rect, rotated_box = get_accurate_rotated_bbox(image, xyxy)\n",
    "      \n",
    "      if rotated_box is not None:\n",
    "          # Draw the rotated bounding box\n",
    "          processed_image = draw_rotated_bbox(processed_image, rotated_box)\n",
    "          \n",
    "          # Get angle and dimensions\n",
    "          center, (width, height), angle = rotated_rect\n",
    "          \n",
    "          # Add text annotations\n",
    "          text = f\"Class: {cls}, Conf: {conf:.2f}\"\n",
    "          cv2.putText(processed_image, text, \n",
    "                     (int(center[0]), int(center[1])), \n",
    "                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "          \n",
    "          print(f\"Object {cls}: Center: {center}, Width: {width:.1f}, Height: {height:.1f}, Angle: {angle:.1f}\")\n",
    "  \n",
    "  return processed_image\n",
    "\n",
    "# Usage example:\n",
    "# Assuming 'image' is your input image and 'detections' contains YOLO detections\n",
    "# image = cv2.imread('your_image.jpg')\n",
    "image_processed = process_detections(image, detections)\n",
    "cv2.imshow('Improved Rotated Bounding Boxes', image_processed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
